{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, LSTM, Dropout, Activation, Permute, GRU, Reshape\n",
    "from keras.layers import MaxPooling2D, Flatten, Conv2D, BatchNormalization, Lambda, Bidirectional, concatenate\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend as K\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import keras.utils\n",
    "from keras.models import load_model\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "set_random_seed(24)\n",
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "spec_path = '../input/spect-scaled/all_spects_scaled.npz'\n",
    "with open(spec_path, 'rb') as handle:\n",
    "    all_spects = np.load(handle)['arr_0']\n",
    "\n",
    "info_path = '../input/track-info/track_info.pickle'\n",
    "with open(info_path, 'rb') as handle:\n",
    "    track_info = pickle.load(handle)\n",
    "\n",
    "track_ids = track_info.index\n",
    "spect_track_id_dict = dict(zip(track_ids, all_spects))\n",
    "\n",
    "enc = LabelEncoder()\n",
    "track_info['labels'] = enc.fit_transform(track_info['genre_top'])\n",
    "y_cat = keras.utils.to_categorical(track_info['labels'].values)\n",
    "track_info['one_hot_labels'] = [y.tolist() for y in y_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_splits(split):\n",
    "    \"\"\"Return spectrogram arrays for the given dataset split\"\"\"\n",
    "    mask = track_info.split == split\n",
    "    ids = track_info.loc[mask].index\n",
    "    data = np.asarray([spect_track_id_dict[i] for i in ids])\n",
    "    data = data.reshape(data.shape[0], data.shape[1], data.shape[2], 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_input_data(split):\n",
    "\n",
    "    assert (split == 'training') or (split == 'validation') or (split == 'test') or (split == 'all')\n",
    "\n",
    "    if split == 'training':\n",
    "        x_train = make_dataset_splits('training')\n",
    "        return x_train\n",
    "    elif split == 'validation':\n",
    "        x_val = make_dataset_splits('validation')\n",
    "        return x_val\n",
    "    elif split == 'test':\n",
    "        x_test = make_dataset_splits('test')\n",
    "        return x_test\n",
    "    else:\n",
    "        x_train = make_dataset_splits('training')\n",
    "        x_val = make_dataset_splits('validation')\n",
    "        x_test = make_dataset_splits('test')\n",
    "        return x_train, x_val, x_test\n",
    "\n",
    "\n",
    "def get_input_shape():\n",
    "\n",
    "    shape = get_input_data(split='test')[0].shape\n",
    "    return shape\n",
    "\n",
    "\n",
    "def make_label_splits(split, label_type = 'one_hot_labels'):\n",
    "    \"\"\"Return response labels for the given dataset split\"\"\"\n",
    "    mask = track_info.split == split\n",
    "    labels = track_info.loc[mask, label_type]\n",
    "    labels = np.asarray([np.array(l) for l in labels])\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_labels(split, label_type = 'one_hot_labels'):\n",
    "    assert (split == 'training') or (split == 'validation') or (split == 'test') or (split == 'all')\n",
    "\n",
    "    if split == 'training':\n",
    "        y_train = make_label_splits('training',label_type)\n",
    "        return y_train\n",
    "    elif split == 'validation':\n",
    "        y_val = make_label_splits('validation',label_type)\n",
    "        return y_val\n",
    "    elif split == 'test':\n",
    "        y_test = make_label_splits('test',label_type)\n",
    "        return y_test\n",
    "    else:\n",
    "        y_train = make_label_splits('training', label_type)\n",
    "        y_val = make_label_splits('validation', label_type)\n",
    "        y_test = make_label_splits('test', label_type)\n",
    "        return y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def get_output_shape():\n",
    "    shape = get_labels(split='test')[0].shape\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(param_grid):\n",
    "    \"\"\"Method for creating a CNN Keras model object with the parameters given by the the param_grid\"\"\"\n",
    "    n_filters = param_grid['n_filters']\n",
    "    filter_size = param_grid['filter_size']\n",
    "    pool_size = param_grid['pool_size']\n",
    "    dropout_rate = param_grid['dropout_rate']\n",
    "    n_cov_layers = param_grid['n_cov_layers']\n",
    "    n_dense_nodes = param_grid['n_dense_nodes']\n",
    "    input_shape = param_grid['input_shape']\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    for i in range(n_cov_layers):\n",
    "        model.add(Conv2D(filters=n_filters, kernel_size=filter_size, activation='relu',\n",
    "                         input_shape=(input_shape[-3], input_shape[-2], 1), padding='same',\n",
    "                         data_format='channels_last', name='conv2d_' + str(i)))\n",
    "        model.add(BatchNormalization(name='batch_norm_' + str(i)))\n",
    "        model.add(Activation('relu', name='relu_' + str(i)))\n",
    "        model.add(MaxPooling2D(pool_size=pool_size, data_format=\"channels_last\", name='max_pool2d_' + str(i)))\n",
    "        model.add(Dropout(dropout_rate, name='dropout_' + str(i)))\n",
    "\n",
    "    model.add(Flatten(name='flatten'))\n",
    "\n",
    "    model.add(Dense(n_dense_nodes, activation='relu', name='dense_1'))\n",
    "    model.add(Dense(n_dense_nodes, activation='relu', name='dense_2'))\n",
    "    model.add(Dense(8, activation='softmax', name='output'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crnn_parallel(param_grid):\n",
    "    \"\"\"Method for creating a CRNN Keras model object with the parameters given by the the param_grid\"\"\"\n",
    "    n_filters = param_grid['n_filters']\n",
    "    filter_size = param_grid['filter_size']\n",
    "    pool_size = param_grid['pool_size']\n",
    "    dropout_rate = param_grid['dropout_rate']\n",
    "    n_cov_layers = param_grid['n_cov_layers']\n",
    "    input_shape = param_grid['input_shape']\n",
    "\n",
    "    input_layer = Input(shape=(input_shape[-3], input_shape[-2], input_shape[-1]),\n",
    "                        name='input')\n",
    "    layer = input_layer\n",
    "    for i in range(n_cov_layers):\n",
    "        layer = Conv2D(filters=n_filters[i], kernel_size=filter_size, padding='valid',\n",
    "                       strides=1, name='conv2d_' + str(i))(layer)\n",
    "        layer = BatchNormalization(axis = 3, name = 'batch_norm' + str(i))(layer)\n",
    "        layer = Activation('relu', name = 'relu' + str(i))(layer)\n",
    "        layer = MaxPooling2D(pool_size=pool_size[i], name='pool2d' + str(i))(layer)\n",
    "        layer = Dropout(dropout_rate, name = 'dropout' + str(i))(layer)\n",
    "\n",
    "    layer = Flatten()(layer)\n",
    "\n",
    "    r_layer = MaxPooling2D(pool_size[5], name='pool_lstm')(input_layer)\n",
    "    r_layer = Lambda(lambda x: K.squeeze(x, axis=-1))(r_layer)\n",
    "\n",
    "    r_layer = Bidirectional(GRU(64), merge_mode='concat')(r_layer)\n",
    "\n",
    "    concat = concatenate([layer, r_layer], axis=-1, name='concat')\n",
    "\n",
    "    output_layer = Dense(8, activation='softmax', name='output')(concat)\n",
    "\n",
    "    opt = RMSprop(lr=0.0005)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,model_name, epochs=20, batch_size=64):\n",
    "    \"\"\"\n",
    "     - Method for training a given Keras model with the given number of training epochs and batch size.\n",
    "     - Methods saves the weights of the best model to a predetermined directory.\n",
    "     - Method includes ModelCheckpoint, ReduceLROnPlateau and TensorBoard callbacks.\n",
    "     - Method returns fitted model and model history\"\"\"\n",
    "\n",
    "    x_train = get_input_data('training')\n",
    "    x_val = get_input_data('validation')\n",
    "\n",
    "    y_train = get_labels('training')\n",
    "    y_val = get_labels('validation')\n",
    "\n",
    "    # Edit path to desired desitation\n",
    "    best_model_path = './models/' + model_name + '/weights.best.h5'\n",
    "    best_model = ModelCheckpoint(best_model_path, monitor='val_acc',\n",
    "                                 save_best_only=True, mode='max')\n",
    "    rp_callback = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=10, min_delta=0.0)\n",
    "\n",
    "    tensorboard_path = './models/' + model_name + '/logs'\n",
    "    tensorboard = TensorBoard(log_dir=tensorboard_path)\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val),\n",
    "                     callbacks=[best_model, rp_callback, tensorboard])\n",
    "    return model, hist\n",
    "\n",
    "\n",
    "def train_cnn():\n",
    "    \"\"\"Train CNN model with validation set preset parameters. Returns the fitted model and training history\"\"\"\n",
    "    param_grid = {'n_filters': 60, 'filter_size': (5, 5), 'pool_size': (2, 2),\n",
    "                  'input_shape': get_input_shape(),\n",
    "                  'dropout_rate': 0.3, 'n_cov_layers': 5, 'n_dense_nodes': 240}\n",
    "\n",
    "    cnn1 = cnn(param_grid)\n",
    "    cnn_fitted, cnn_history = train_model(cnn1, model_name='cnn1')\n",
    "\n",
    "    return cnn_fitted, cnn_history\n",
    "\n",
    "\n",
    "def train_crnn_parallel():\n",
    "    \"\"\"Train CRNN model with validation set preset parameters. Returns the fitted model and training history\"\"\"\n",
    "    crnn_parallel_param_grid = dict(n_filters=[16, 32, 64, 64, 64], filter_size=(3, 1),\n",
    "                                    pool_size=[(2, 2), (2, 2), (2, 2), (4, 4), (4, 4), (4, 2)], dropout_rate=0.3,\n",
    "                                    n_cov_layers=5, n_recurrent_layers=2, n_time_layers=1, n_time_dst_nodes=128,\n",
    "                                    n_dense_nodes=240, l2=.001, input_shape=get_input_shape(),\n",
    "                                    output_shape=get_output_shape())\n",
    "    crnn_parallel1 = crnn_parallel(crnn_parallel_param_grid)\n",
    "    crnn_parallel_fitted , crnn_parallel_history = train_model(crnn_parallel1, model_name = 'crnn_parallel1', epochs = 50)\n",
    "\n",
    "    return crnn_parallel_fitted, crnn_parallel_history\n",
    "\n",
    "\n",
    "def predict_model(model, model_name):\n",
    "    \"\"\"\n",
    "    Predict the training, validation, and testing accurcary for the given keras model.\n",
    "    Returns pandas dataframes of the predictions for training, validation, and testing datasets\n",
    "    Returns pandas series of the macro f1 scores for each dataset split \"\"\"\n",
    "\n",
    "    x_train, x_val, x_test = get_input_data('all')\n",
    "    y_train, y_val, y_test = get_labels('all')\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "    val_loss, val_acc = model.evaluate(x_val, y_val)\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "    print('Training set Accuracy: ', train_acc)\n",
    "    print('Validation set Accuracy: ', val_acc)\n",
    "    print('Test set Accuracy: ', test_acc)\n",
    "\n",
    "    train_predictions = model.predict(x_train)\n",
    "    val_predictions = model.predict(x_val)\n",
    "    test_predictions = model.predict(x_test)\n",
    "\n",
    "    train_pred_classes = train_predictions.argmax(axis=-1)\n",
    "    val_pred_classes = val_predictions.argmax(axis=-1)\n",
    "    test_pred_classes = test_predictions.argmax(axis=-1)\n",
    "    \n",
    "    y_train, y_val, y_test = get_labels('all', label_type = 'labels')\n",
    "\n",
    "    train_f1 = f1_score(y_train, train_pred_classes, average = 'macro')\n",
    "    val_f1 = f1_score(y_val, val_pred_classes, average='macro')\n",
    "    test_f1 = f1_score(y_test, test_pred_classes, average='macro')\n",
    "\n",
    "    f1_scores = pd.Series({'Training': train_f1, 'Validation': val_f1, 'Testing': test_f1})\n",
    "    f1_scores.name = model_name\n",
    "\n",
    "    train_predictions_df = pd.DataFrame(train_predictions, columns=[l + '_prob' for l in enc.classes_],\n",
    "                                        index=track_info.loc[track_info.split == 'training'].index)\n",
    "    val_predictions_df = pd.DataFrame(val_predictions, columns=[l + '_prob' for l in enc.classes_],\n",
    "                                      index=track_info.loc[track_info.split == 'validation'].index)\n",
    "    test_predictions_df = pd.DataFrame(test_predictions, columns=[l + '_prob' for l in enc.classes_],\n",
    "                                       index=track_info.loc[track_info.split == 'test'].index)\n",
    "\n",
    "    return train_predictions_df, val_predictions_df, test_predictions_df, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6394 samples, validate on 800 samples\n",
      "Epoch 1/20\n",
      "6394/6394 [==============================] - 35s 6ms/step - loss: 2.1138 - acc: 0.2789 - val_loss: 2.0317 - val_acc: 0.1575\n",
      "Epoch 2/20\n",
      "6394/6394 [==============================] - 30s 5ms/step - loss: 1.6587 - acc: 0.3863 - val_loss: 2.0348 - val_acc: 0.1900\n",
      "Epoch 3/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.5677 - acc: 0.4346 - val_loss: 12.2207 - val_acc: 0.1237\n",
      "Epoch 4/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.4979 - acc: 0.4690 - val_loss: 2.0090 - val_acc: 0.3262\n",
      "Epoch 5/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.4347 - acc: 0.4916 - val_loss: 1.7868 - val_acc: 0.3775\n",
      "Epoch 6/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.3853 - acc: 0.5106 - val_loss: 1.8265 - val_acc: 0.3212\n",
      "Epoch 7/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.3358 - acc: 0.5246 - val_loss: 1.8580 - val_acc: 0.3450\n",
      "Epoch 8/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.2969 - acc: 0.5343 - val_loss: 1.9202 - val_acc: 0.2137\n",
      "Epoch 9/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.2533 - acc: 0.5608 - val_loss: 1.9317 - val_acc: 0.3350\n",
      "Epoch 10/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.2323 - acc: 0.5641 - val_loss: 5.2655 - val_acc: 0.1638\n",
      "Epoch 11/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.1950 - acc: 0.5838 - val_loss: 5.9125 - val_acc: 0.1412\n",
      "Epoch 12/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.1655 - acc: 0.5938 - val_loss: 1.6833 - val_acc: 0.3900\n",
      "Epoch 13/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.1137 - acc: 0.6078 - val_loss: 1.7263 - val_acc: 0.3900\n",
      "Epoch 14/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.1106 - acc: 0.6107 - val_loss: 3.1532 - val_acc: 0.2463\n",
      "Epoch 15/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.0653 - acc: 0.6281 - val_loss: 2.0782 - val_acc: 0.2913\n",
      "Epoch 16/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.0451 - acc: 0.6331 - val_loss: 2.0992 - val_acc: 0.3650\n",
      "Epoch 17/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 1.0033 - acc: 0.6525 - val_loss: 3.5470 - val_acc: 0.2325\n",
      "Epoch 18/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 0.9824 - acc: 0.6509 - val_loss: 6.7492 - val_acc: 0.1713\n",
      "Epoch 19/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 0.9435 - acc: 0.6708 - val_loss: 3.2172 - val_acc: 0.2637\n",
      "Epoch 20/20\n",
      "6394/6394 [==============================] - 31s 5ms/step - loss: 0.9255 - acc: 0.6666 - val_loss: 1.6438 - val_acc: 0.4238\n"
     ]
    }
   ],
   "source": [
    "cnn_fitted, cnn_history = train_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6394/6394 [==============================] - 12s 2ms/step\n",
      "800/800 [==============================] - 1s 2ms/step\n",
      "800/800 [==============================] - 1s 2ms/step\n",
      "Training set Accuracy:  0.4879574601281834\n",
      "Validation set Accuracy:  0.42375\n",
      "Test set Accuracy:  0.35375\n"
     ]
    }
   ],
   "source": [
    "train_predictions_df, val_predictions_df, test_predictions_df, cnn_f1_scores = predict_model(cnn_fitted, 'CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training      0.489975\n",
       "Validation    0.420764\n",
       "Testing       0.343055\n",
       "Name: CNN, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6394 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "6394/6394 [==============================] - 61s 10ms/step - loss: 2.5431 - acc: 0.1950 - val_loss: 2.0438 - val_acc: 0.2313\n",
      "Epoch 2/50\n",
      "6394/6394 [==============================] - 58s 9ms/step - loss: 2.1225 - acc: 0.2687 - val_loss: 2.2784 - val_acc: 0.1487\n",
      "Epoch 3/50\n",
      "6394/6394 [==============================] - 57s 9ms/step - loss: 1.9294 - acc: 0.3036 - val_loss: 2.0405 - val_acc: 0.1775\n",
      "Epoch 4/50\n",
      "6394/6394 [==============================] - 57s 9ms/step - loss: 1.7896 - acc: 0.3427 - val_loss: 2.0590 - val_acc: 0.1838\n",
      "Epoch 5/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.7600 - acc: 0.3536 - val_loss: 1.8475 - val_acc: 0.2938\n",
      "Epoch 6/50\n",
      "6394/6394 [==============================] - 53s 8ms/step - loss: 1.7010 - acc: 0.3811 - val_loss: 1.9571 - val_acc: 0.2375\n",
      "Epoch 7/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.6563 - acc: 0.3929 - val_loss: 1.7686 - val_acc: 0.2988\n",
      "Epoch 8/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.6317 - acc: 0.4071 - val_loss: 1.9320 - val_acc: 0.2787\n",
      "Epoch 9/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.5890 - acc: 0.4234 - val_loss: 1.8147 - val_acc: 0.3013\n",
      "Epoch 10/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.5674 - acc: 0.4313 - val_loss: 1.7365 - val_acc: 0.3287\n",
      "Epoch 11/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.5399 - acc: 0.4440 - val_loss: 1.8253 - val_acc: 0.3200\n",
      "Epoch 12/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.5180 - acc: 0.4567 - val_loss: 1.8062 - val_acc: 0.3212\n",
      "Epoch 13/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.5024 - acc: 0.4639 - val_loss: 1.7151 - val_acc: 0.3638\n",
      "Epoch 14/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.4901 - acc: 0.4698 - val_loss: 1.6708 - val_acc: 0.3588\n",
      "Epoch 15/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.4660 - acc: 0.4801 - val_loss: 1.5924 - val_acc: 0.4175\n",
      "Epoch 16/50\n",
      "6394/6394 [==============================] - 55s 9ms/step - loss: 1.4620 - acc: 0.4723 - val_loss: 1.6639 - val_acc: 0.3600\n",
      "Epoch 17/50\n",
      "6394/6394 [==============================] - 53s 8ms/step - loss: 1.4429 - acc: 0.4808 - val_loss: 1.6626 - val_acc: 0.3775\n",
      "Epoch 18/50\n",
      "6394/6394 [==============================] - 53s 8ms/step - loss: 1.4275 - acc: 0.4925 - val_loss: 1.6588 - val_acc: 0.3738\n",
      "Epoch 19/50\n",
      "6394/6394 [==============================] - 53s 8ms/step - loss: 1.4066 - acc: 0.5102 - val_loss: 1.5825 - val_acc: 0.4113\n",
      "Epoch 20/50\n",
      "6394/6394 [==============================] - 53s 8ms/step - loss: 1.4000 - acc: 0.5027 - val_loss: 1.6080 - val_acc: 0.3700\n",
      "Epoch 21/50\n",
      "6394/6394 [==============================] - 53s 8ms/step - loss: 1.3860 - acc: 0.5075 - val_loss: 1.6600 - val_acc: 0.3787\n",
      "Epoch 22/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.3755 - acc: 0.5139 - val_loss: 1.6439 - val_acc: 0.4062\n",
      "Epoch 23/50\n",
      "6394/6394 [==============================] - 53s 8ms/step - loss: 1.3637 - acc: 0.5175 - val_loss: 1.5314 - val_acc: 0.4275\n",
      "Epoch 24/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.3465 - acc: 0.5210 - val_loss: 1.5985 - val_acc: 0.4263\n",
      "Epoch 25/50\n",
      "6394/6394 [==============================] - 55s 9ms/step - loss: 1.3417 - acc: 0.5185 - val_loss: 1.5809 - val_acc: 0.4200\n",
      "Epoch 26/50\n",
      "6394/6394 [==============================] - 56s 9ms/step - loss: 1.3286 - acc: 0.5349 - val_loss: 1.5962 - val_acc: 0.4363\n",
      "Epoch 27/50\n",
      "6394/6394 [==============================] - 57s 9ms/step - loss: 1.3080 - acc: 0.5450 - val_loss: 1.5805 - val_acc: 0.4437\n",
      "Epoch 28/50\n",
      "6394/6394 [==============================] - 55s 9ms/step - loss: 1.3061 - acc: 0.5424 - val_loss: 1.5205 - val_acc: 0.4338\n",
      "Epoch 29/50\n",
      "6394/6394 [==============================] - 54s 9ms/step - loss: 1.3061 - acc: 0.5450 - val_loss: 1.5915 - val_acc: 0.4213\n",
      "Epoch 30/50\n",
      "6394/6394 [==============================] - 55s 9ms/step - loss: 1.3036 - acc: 0.5397 - val_loss: 1.5586 - val_acc: 0.4425\n",
      "Epoch 31/50\n",
      "6394/6394 [==============================] - 55s 9ms/step - loss: 1.2796 - acc: 0.5515 - val_loss: 1.5947 - val_acc: 0.4412\n",
      "Epoch 32/50\n",
      "6394/6394 [==============================] - 55s 9ms/step - loss: 1.2792 - acc: 0.5504 - val_loss: 1.4813 - val_acc: 0.4888\n",
      "Epoch 33/50\n",
      "6394/6394 [==============================] - 55s 9ms/step - loss: 1.2722 - acc: 0.5565 - val_loss: 1.4860 - val_acc: 0.4662\n",
      "Epoch 34/50\n",
      "6394/6394 [==============================] - 55s 9ms/step - loss: 1.2650 - acc: 0.5613 - val_loss: 1.5853 - val_acc: 0.4387\n",
      "Epoch 35/50\n",
      "6394/6394 [==============================] - 55s 9ms/step - loss: 1.2459 - acc: 0.5652 - val_loss: 1.7922 - val_acc: 0.3738\n",
      "Epoch 36/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.2364 - acc: 0.5688 - val_loss: 1.5412 - val_acc: 0.4613\n",
      "Epoch 37/50\n",
      "6394/6394 [==============================] - 54s 9ms/step - loss: 1.2405 - acc: 0.5696 - val_loss: 1.6039 - val_acc: 0.4338\n",
      "Epoch 38/50\n",
      "6394/6394 [==============================] - 55s 9ms/step - loss: 1.2226 - acc: 0.5705 - val_loss: 1.7163 - val_acc: 0.3875\n",
      "Epoch 39/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.2189 - acc: 0.5730 - val_loss: 1.6216 - val_acc: 0.4200\n",
      "Epoch 40/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.2110 - acc: 0.5804 - val_loss: 1.5789 - val_acc: 0.4450\n",
      "Epoch 41/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.2097 - acc: 0.5732 - val_loss: 1.5144 - val_acc: 0.4688\n",
      "Epoch 42/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.2026 - acc: 0.5796 - val_loss: 1.5800 - val_acc: 0.4562\n",
      "Epoch 43/50\n",
      "6394/6394 [==============================] - 56s 9ms/step - loss: 1.1446 - acc: 0.6068 - val_loss: 1.6016 - val_acc: 0.4487\n",
      "Epoch 44/50\n",
      "6394/6394 [==============================] - 56s 9ms/step - loss: 1.1389 - acc: 0.6034 - val_loss: 1.5648 - val_acc: 0.4700\n",
      "Epoch 45/50\n",
      "6394/6394 [==============================] - 54s 9ms/step - loss: 1.1342 - acc: 0.6045 - val_loss: 1.5609 - val_acc: 0.4587\n",
      "Epoch 46/50\n",
      "6394/6394 [==============================] - 54s 9ms/step - loss: 1.1250 - acc: 0.6153 - val_loss: 1.5023 - val_acc: 0.4838\n",
      "Epoch 47/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.1198 - acc: 0.6167 - val_loss: 1.5890 - val_acc: 0.4412\n",
      "Epoch 48/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.1153 - acc: 0.6071 - val_loss: 1.4723 - val_acc: 0.4788\n",
      "Epoch 49/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.1114 - acc: 0.6170 - val_loss: 1.5372 - val_acc: 0.4662\n",
      "Epoch 50/50\n",
      "6394/6394 [==============================] - 54s 8ms/step - loss: 1.1153 - acc: 0.6195 - val_loss: 1.5510 - val_acc: 0.4725\n"
     ]
    }
   ],
   "source": [
    "#crnn_parallel_param_grid = dict(n_filters=[16, 32, 64, 64, 64], filter_size=(3, 1),\n",
    "                                    #pool_size=[(2, 2), (2, 2), (2, 2), (4, 4), (4, 4), (4, 2)], dropout_rate=0.3,\n",
    "                                    #n_cov_layers=5, n_recurrent_layers=2, n_time_layers=1, n_time_dst_nodes=128,\n",
    "                                    #n_dense_nodes=240, l2=.001, input_shape=get_input_shape(),\n",
    "                                    #output_shape=get_output_shape())\n",
    "#crnn_parallel = crnn_parallel(crnn_parallel_param_grid)\n",
    "crnn_parallel_fitted, crnn_parallel_history = train_crnn_parallel()\n",
    "#crnn_weights_path = '../input/crnn-parallel/weights.best.h5'\n",
    "#crnn_parallel.load_weights(crnn_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6394/6394 [==============================] - 37s 6ms/step\n",
      "800/800 [==============================] - 5s 6ms/step\n",
      "800/800 [==============================] - 5s 6ms/step\n",
      "Training set Accuracy:  0.5652173912857039\n",
      "Validation set Accuracy:  0.4725\n",
      "Test set Accuracy:  0.36625\n"
     ]
    }
   ],
   "source": [
    "train_pred_df, val_pred_df, test_pred_df, crnn_f1_scores = predict_model(crnn_parallel_fitted, 'CRNN Parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training      0.544224\n",
       "Validation    0.441026\n",
       "Testing       0.336959\n",
       "Name: CRNN Parallel, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnn_f1_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
